#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
è­¦å‘Šæ­·å²æ•¸æ“šåˆ†æç³»çµ±
åŠŸèƒ½ï¼š
1. è­¦å‘Šæ•¸æ“šæ”¶é›†å’Œå­˜å„²
2. æ­·å²è¶¨å‹¢åˆ†æ
3. å­£ç¯€æ€§æ¨¡å¼è­˜åˆ¥
4. é æ¸¬æº–ç¢ºæ€§è©•ä¼°
5. è­¦å‘Šå½±éŸ¿æ•ˆæœè©•ä¼°
"""

import json
import sqlite3
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import os
from collections import defaultdict, Counter
import statistics
from typing import Dict, List, Tuple, Optional

class WarningHistoryAnalyzer:
    """è­¦å‘Šæ­·å²æ•¸æ“šåˆ†æå™¨"""
    
    def __init__(self, db_path="warning_history.db"):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        self.db_path = db_path
        self.init_database()
        print(f"ğŸ“Š è­¦å‘Šæ­·å²åˆ†æå™¨å·²åˆå§‹åŒ– - æ•¸æ“šåº«: {db_path}")
    
    def init_database(self):
        """åˆå§‹åŒ–æ•¸æ“šåº«çµæ§‹"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # è­¦å‘Šè¨˜éŒ„è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS warning_records (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT NOT NULL,
                warning_text TEXT NOT NULL,
                category TEXT,
                subcategory TEXT,
                severity TEXT,
                level INTEGER,
                impact_score REAL,
                area_specific BOOLEAN,
                duration_hint TEXT,
                time_of_day TEXT,
                season TEXT,
                weather_context TEXT,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # é æ¸¬è¨˜éŒ„è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS prediction_records (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT NOT NULL,
                prediction_type TEXT,
                advance_hours INTEGER,
                original_score REAL,
                warning_impact REAL,
                warning_risk_impact REAL,
                final_score REAL,
                actual_result TEXT,
                accuracy_score REAL,
                warnings_active TEXT,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # è­¦å‘Šå½±éŸ¿è©•ä¼°è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS warning_impact_analysis (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                warning_id INTEGER,
                prediction_id INTEGER,
                impact_type TEXT,
                expected_impact REAL,
                actual_impact REAL,
                accuracy_rating TEXT,
                notes TEXT,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (warning_id) REFERENCES warning_records (id),
                FOREIGN KEY (prediction_id) REFERENCES prediction_records (id)
            )
        ''')
        
        conn.commit()
        conn.close()
        print("âœ… æ•¸æ“šåº«çµæ§‹åˆå§‹åŒ–å®Œæˆ")
    
    def record_warning(self, warning_data: Dict, weather_context: Dict = None) -> int:
        """è¨˜éŒ„è­¦å‘Šæ•¸æ“š"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        timestamp = datetime.now().isoformat()
        
        # è§£æè­¦å‘Šä¿¡æ¯ï¼ˆé‡ç”¨app.pyä¸­çš„å‡½æ•¸é‚è¼¯ï¼‰
        warning_info = self._parse_warning_for_storage(warning_data)
        
        # ç²å–ç’°å¢ƒä¿¡æ¯
        current_hour = datetime.now().hour
        current_month = datetime.now().month
        
        time_of_day = 'day'
        if 17 <= current_hour <= 19:
            time_of_day = 'sunset'
        elif 5 <= current_hour <= 7:
            time_of_day = 'sunrise'
        
        season = 'summer'
        if current_month in [12, 1, 2]:
            season = 'winter'
        elif current_month in [3, 4, 5]:
            season = 'spring'
        elif current_month in [9, 10, 11]:
            season = 'autumn'
        
        cursor.execute('''
            INSERT INTO warning_records 
            (timestamp, warning_text, category, subcategory, severity, level, 
             impact_score, area_specific, duration_hint, time_of_day, season, weather_context)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            timestamp,
            warning_info['warning_text'],
            warning_info['category'],
            warning_info['subcategory'],
            warning_info['severity'],
            warning_info['level'],
            warning_info['impact_score'],
            warning_info['area_specific'],
            warning_info['duration_hint'],
            time_of_day,
            season,
            json.dumps(weather_context) if weather_context else None
        ))
        
        warning_id = cursor.lastrowid
        conn.commit()
        conn.close()
        
        print(f"ğŸ“ å·²è¨˜éŒ„è­¦å‘Š: {warning_info['category']}-{warning_info['severity']} (ID: {warning_id})")
        return warning_id
    
    def record_prediction(self, prediction_data: Dict) -> int:
        """è¨˜éŒ„é æ¸¬æ•¸æ“š"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        timestamp = datetime.now().isoformat()
        
        cursor.execute('''
            INSERT INTO prediction_records 
            (timestamp, prediction_type, advance_hours, original_score, warning_impact, 
             warning_risk_impact, final_score, warnings_active)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            timestamp,
            prediction_data.get('prediction_type', 'sunset'),
            prediction_data.get('advance_hours', 0),
            prediction_data.get('original_score', 0),
            prediction_data.get('warning_impact', 0),
            prediction_data.get('warning_risk_impact', 0),
            prediction_data.get('final_score', 0),
            json.dumps(prediction_data.get('warnings_active', []))
        ))
        
        prediction_id = cursor.lastrowid
        conn.commit()
        conn.close()
        
        print(f"ğŸ“ˆ å·²è¨˜éŒ„é æ¸¬: {prediction_data.get('prediction_type')} (ID: {prediction_id})")
        return prediction_id
    
    def analyze_warning_patterns(self, days_back: int = 30) -> Dict:
        """åˆ†æè­¦å‘Šæ¨¡å¼"""
        conn = sqlite3.connect(self.db_path)
        
        # è¨ˆç®—æ™‚é–“ç¯„åœ
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days_back)
        
        # æŸ¥è©¢è­¦å‘Šæ•¸æ“š
        query = '''
            SELECT * FROM warning_records 
            WHERE timestamp >= ? AND timestamp <= ?
            ORDER BY timestamp DESC
        '''
        
        df = pd.read_sql_query(query, conn, params=(start_date.isoformat(), end_date.isoformat()))
        conn.close()
        
        if len(df) == 0:
            return {"message": "æŒ‡å®šæœŸé–“å…§ç„¡è­¦å‘Šæ•¸æ“š", "period": f"{days_back}å¤©"}
        
        analysis = {
            "analysis_period": f"{days_back}å¤©",
            "total_warnings": len(df),
            "date_range": {
                "start": start_date.strftime("%Y-%m-%d"),
                "end": end_date.strftime("%Y-%m-%d")
            }
        }
        
        # 1. è­¦å‘Šé¡åˆ¥åˆ†å¸ƒ
        category_dist = df['category'].value_counts().to_dict()
        analysis['category_distribution'] = category_dist
        
        # 2. åš´é‡åº¦åˆ†å¸ƒ
        severity_dist = df['severity'].value_counts().to_dict()
        analysis['severity_distribution'] = severity_dist
        
        # 3. æ™‚é–“åˆ†å¸ƒåˆ†æ
        df['hour'] = pd.to_datetime(df['timestamp']).dt.hour
        df['day_of_week'] = pd.to_datetime(df['timestamp']).dt.day_name()
        
        hour_dist = df['hour'].value_counts().sort_index().to_dict()
        dow_dist = df['day_of_week'].value_counts().to_dict()
        
        analysis['temporal_patterns'] = {
            "hourly_distribution": hour_dist,
            "day_of_week_distribution": dow_dist
        }
        
        # 4. å­£ç¯€æ€§åˆ†æ
        season_dist = df['season'].value_counts().to_dict()
        analysis['seasonal_patterns'] = season_dist
        
        # 5. å½±éŸ¿åˆ†æ•¸çµ±è¨ˆ
        impact_stats = {
            "mean": round(df['impact_score'].mean(), 2),
            "median": round(df['impact_score'].median(), 2),
            "max": round(df['impact_score'].max(), 2),
            "min": round(df['impact_score'].min(), 2),
            "std": round(df['impact_score'].std(), 2)
        }
        analysis['impact_score_statistics'] = impact_stats
        
        # 6. é«˜å½±éŸ¿è­¦å‘Šè­˜åˆ¥
        high_impact_threshold = df['impact_score'].quantile(0.8)
        high_impact_warnings = df[df['impact_score'] >= high_impact_threshold]
        
        analysis['high_impact_warnings'] = {
            "threshold": round(high_impact_threshold, 2),
            "count": len(high_impact_warnings),
            "percentage": round(len(high_impact_warnings) / len(df) * 100, 1),
            "most_common_categories": high_impact_warnings['category'].value_counts().head(3).to_dict()
        }
        
        # 7. åœ°å€æ€§è­¦å‘Šåˆ†æ
        area_specific_count = len(df[df['area_specific'] == True])
        analysis['area_specific_analysis'] = {
            "total_area_specific": area_specific_count,
            "percentage": round(area_specific_count / len(df) * 100, 1),
            "hong_kong_wide": len(df) - area_specific_count
        }
        
        return analysis
    
    def analyze_seasonal_trends(self) -> Dict:
        """åˆ†æå­£ç¯€æ€§è¶¨å‹¢"""
        conn = sqlite3.connect(self.db_path)
        
        query = '''
            SELECT season, category, severity, impact_score, 
                   COUNT(*) as frequency,
                   AVG(impact_score) as avg_impact
            FROM warning_records 
            GROUP BY season, category, severity
            ORDER BY season, frequency DESC
        '''
        
        df = pd.read_sql_query(query, conn)
        conn.close()
        
        if len(df) == 0:
            return {"message": "ç„¡è¶³å¤ æ•¸æ“šé€²è¡Œå­£ç¯€æ€§åˆ†æ"}
        
        seasonal_analysis = {}
        
        for season in df['season'].unique():
            season_data = df[df['season'] == season]
            
            seasonal_analysis[season] = {
                "total_warnings": season_data['frequency'].sum(),
                "most_common_categories": season_data.groupby('category')['frequency'].sum().sort_values(ascending=False).head(3).to_dict(),
                "severity_distribution": season_data.groupby('severity')['frequency'].sum().to_dict(),
                "average_impact_by_category": season_data.groupby('category')['avg_impact'].mean().round(2).to_dict(),
                "highest_impact_warnings": season_data.nlargest(3, 'avg_impact')[['category', 'severity', 'avg_impact']].to_dict('records')
            }
        
        # å­£ç¯€æ¯”è¼ƒ
        seasonal_comparison = {
            "most_active_season": df.groupby('season')['frequency'].sum().idxmax(),
            "highest_impact_season": df.groupby('season')['avg_impact'].mean().idxmax(),
            "seasonal_impact_ranking": df.groupby('season')['avg_impact'].mean().sort_values(ascending=False).to_dict()
        }
        
        return {
            "seasonal_breakdown": seasonal_analysis,
            "seasonal_comparison": seasonal_comparison,
            "analysis_note": "åŸºæ–¼æ­·å²è­¦å‘Šæ•¸æ“šçš„å­£ç¯€æ€§æ¨¡å¼åˆ†æ"
        }
    
    def evaluate_prediction_accuracy(self, days_back: int = 7) -> Dict:
        """è©•ä¼°é æ¸¬æº–ç¢ºæ€§"""
        conn = sqlite3.connect(self.db_path)
        
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days_back)
        
        # æŸ¥è©¢é æ¸¬è¨˜éŒ„
        query = '''
            SELECT * FROM prediction_records 
            WHERE timestamp >= ? AND timestamp <= ?
            AND actual_result IS NOT NULL
            ORDER BY timestamp DESC
        '''
        
        df = pd.read_sql_query(query, conn, params=(start_date.isoformat(), end_date.isoformat()))
        conn.close()
        
        if len(df) == 0:
            return {"message": f"éå»{days_back}å¤©å…§ç„¡è¶³å¤ é æ¸¬æ•¸æ“šé€²è¡Œæº–ç¢ºæ€§è©•ä¼°"}
        
        accuracy_analysis = {
            "evaluation_period": f"{days_back}å¤©",
            "total_predictions": len(df),
            "evaluated_predictions": len(df[df['actual_result'].notna()])
        }
        
        # è­¦å‘Šå½±éŸ¿æº–ç¢ºæ€§
        if 'accuracy_score' in df.columns:
            accuracy_stats = {
                "mean_accuracy": round(df['accuracy_score'].mean(), 2),
                "median_accuracy": round(df['accuracy_score'].median(), 2),
                "accuracy_above_80": len(df[df['accuracy_score'] >= 0.8]),
                "accuracy_below_60": len(df[df['accuracy_score'] < 0.6])
            }
            accuracy_analysis['accuracy_statistics'] = accuracy_stats
        
        # è­¦å‘Šå½±éŸ¿æ•ˆæœåˆ†æ
        warning_impact_analysis = {
            "predictions_with_warnings": len(df[df['warning_impact'] > 0]),
            "average_warning_impact": round(df['warning_impact'].mean(), 2),
            "max_warning_impact": round(df['warning_impact'].max(), 2),
            "warning_risk_predictions": len(df[df['warning_risk_impact'] > 0]),
            "average_risk_impact": round(df['warning_risk_impact'].mean(), 2)
        }
        accuracy_analysis['warning_impact_analysis'] = warning_impact_analysis
        
        # æŒ‰é æ¸¬é¡å‹åˆ†æ
        type_analysis = {}
        for pred_type in df['prediction_type'].unique():
            type_data = df[df['prediction_type'] == pred_type]
            type_analysis[pred_type] = {
                "count": len(type_data),
                "avg_accuracy": round(type_data['accuracy_score'].mean(), 2) if 'accuracy_score' in type_data.columns else None,
                "avg_warning_impact": round(type_data['warning_impact'].mean(), 2)
            }
        
        accuracy_analysis['by_prediction_type'] = type_analysis
        
        return accuracy_analysis
    
    def generate_warning_insights(self) -> Dict:
        """ç”Ÿæˆè­¦å‘Šæ•¸æ“šæ´å¯Ÿ"""
        # ç¶œåˆåˆ†æ
        patterns = self.analyze_warning_patterns(30)
        seasonal = self.analyze_seasonal_trends()
        accuracy = self.evaluate_prediction_accuracy(7)
        
        insights = {
            "analysis_timestamp": datetime.now().isoformat(),
            "summary": {
                "total_warnings_30d": patterns.get('total_warnings', 0),
                "most_common_warning": max(patterns.get('category_distribution', {}).items(), key=lambda x: x[1]) if patterns.get('category_distribution') else None,
                "highest_impact_category": None,
                "seasonal_trend": seasonal.get('seasonal_comparison', {}).get('most_active_season'),
                "prediction_accuracy": accuracy.get('accuracy_statistics', {}).get('mean_accuracy')
            },
            "recommendations": [],
            "data_quality": self._assess_data_quality()
        }
        
        # ç”Ÿæˆå»ºè­°
        recommendations = []
        
        if patterns.get('total_warnings', 0) > 0:
            high_impact = patterns.get('high_impact_warnings', {})
            if high_impact.get('percentage', 0) > 20:
                recommendations.append("å»ºè­°åŠ å¼·é«˜å½±éŸ¿è­¦å‘Šçš„é æ¸¬æ¨¡å‹æ¬Šé‡")
            
            category_dist = patterns.get('category_distribution', {})
            if category_dist:
                most_common = max(category_dist.items(), key=lambda x: x[1])
                recommendations.append(f"æœ€å¸¸è¦‹è­¦å‘Šé¡å‹ç‚º{most_common[0]}ï¼Œå»ºè­°å„ªåŒ–æ­¤é¡è­¦å‘Šçš„è™•ç†é‚è¼¯")
        
        if seasonal.get('seasonal_comparison'):
            most_active = seasonal['seasonal_comparison'].get('most_active_season')
            if most_active:
                recommendations.append(f"{most_active}å­£ç¯€è­¦å‘Šæœ€é »ç¹ï¼Œå»ºè­°å¢å¼·è©²å­£ç¯€çš„é æ¸¬æ•æ„Ÿåº¦")
        
        if accuracy.get('accuracy_statistics'):
            acc_stats = accuracy['accuracy_statistics']
            if acc_stats.get('mean_accuracy', 0) < 0.7:
                recommendations.append("é æ¸¬æº–ç¢ºæ€§åä½ï¼Œå»ºè­°èª¿æ•´è­¦å‘Šå½±éŸ¿è¨ˆç®—ç®—æ³•")
        
        insights['recommendations'] = recommendations
        
        return insights
    
    def export_analysis_report(self, output_file: str = None) -> str:
        """å°å‡ºåˆ†æå ±å‘Š"""
        if output_file is None:
            output_file = f"warning_analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        # ç”Ÿæˆå®Œæ•´å ±å‘Š
        report = {
            "report_metadata": {
                "generated_at": datetime.now().isoformat(),
                "report_type": "è­¦å‘Šæ­·å²æ•¸æ“šåˆ†æå ±å‘Š",
                "version": "1.0"
            },
            "pattern_analysis": self.analyze_warning_patterns(30),
            "seasonal_analysis": self.analyze_seasonal_trends(),
            "accuracy_evaluation": self.evaluate_prediction_accuracy(7),
            "insights_and_recommendations": self.generate_warning_insights()
        }
        
        # ä¿å­˜å ±å‘Š
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“Š åˆ†æå ±å‘Šå·²å°å‡º: {output_file}")
        return output_file
    
    def _parse_warning_for_storage(self, warning_data: Dict) -> Dict:
        """è§£æè­¦å‘Šæ•¸æ“šç”¨æ–¼å­˜å„² - å¢å¼·ç‰ˆï¼Œæ”¯æŒJSONæ ¼å¼è­¦å‘Š"""
        import json
        import ast
        
        # æå–è­¦å‘Šæ–‡æœ¬å’Œä»£ç¢¼
        warning_text = ""
        warning_code = ""
        
        if isinstance(warning_data, str):
            # å˜—è©¦è§£æJSONå­—ç¬¦ä¸²æ ¼å¼çš„è­¦å‘Š
            try:
                if warning_data.startswith('{') and warning_data.endswith('}'):
                    parsed_data = ast.literal_eval(warning_data)
                    if isinstance(parsed_data, dict):
                        # æå–contentsæ•¸çµ„ä¸¦åˆä½µ
                        if 'contents' in parsed_data and isinstance(parsed_data['contents'], list):
                            warning_text = ' '.join(parsed_data['contents'])
                        else:
                            warning_text = str(parsed_data)
                        warning_code = parsed_data.get('warningStatementCode', '')
                    else:
                        warning_text = warning_data
                else:
                    warning_text = warning_data
            except:
                warning_text = warning_data
        else:
            # è™•ç†å­—å…¸æ ¼å¼
            if 'contents' in warning_data and isinstance(warning_data['contents'], list):
                warning_text = ' '.join(warning_data['contents'])
            else:
                warning_text = warning_data.get('warning_text', str(warning_data))
            warning_code = warning_data.get('warningStatementCode', '')
        
        # åˆå§‹åŒ–è­¦å‘Šä¿¡æ¯
        warning_info = {
            'warning_text': warning_text,
            'category': 'unknown',
            'subcategory': '',
            'severity': 'low',
            'level': 0,
            'impact_score': 0,
            'area_specific': False,
            'duration_hint': '',
            'warning_code': warning_code
        }
        
        text_lower = warning_text.lower()
        
        # 1. å„ªå…ˆä½¿ç”¨å®˜æ–¹è­¦å‘Šä»£ç¢¼åˆ†é¡
        if warning_code:
            if warning_code == 'WTS':
                warning_info['category'] = 'thunderstorm'
                warning_info['subcategory'] = 'general_thunderstorm'
                warning_info['severity'] = 'moderate'
                warning_info['level'] = 2
                warning_info['impact_score'] = 10
            elif warning_code == 'WHOT':
                warning_info['category'] = 'temperature'
                warning_info['subcategory'] = 'extreme_heat'
                warning_info['severity'] = 'moderate'
                warning_info['level'] = 2
                warning_info['impact_score'] = 8
            elif warning_code == 'WCOLD':
                warning_info['category'] = 'temperature'
                warning_info['subcategory'] = 'extreme_cold'
                warning_info['severity'] = 'moderate'
                warning_info['level'] = 2
                warning_info['impact_score'] = 6
            elif warning_code == 'WTCSGNL':
                warning_info['category'] = 'wind_storm'
                warning_info['subcategory'] = 'tropical_cyclone'
                warning_info['severity'] = 'severe'
                warning_info['level'] = 3
                warning_info['impact_score'] = 20
            elif warning_code in ['WFNTSA', 'WL']:
                warning_info['category'] = 'wind_storm'
                warning_info['subcategory'] = 'strong_wind'
                warning_info['severity'] = 'moderate'
                warning_info['level'] = 2
                warning_info['impact_score'] = 12
            elif warning_code in ['WRAIN', 'WR']:
                warning_info['category'] = 'rainfall'
                warning_info['subcategory'] = 'heavy_rain'
                warning_info['severity'] = 'moderate'
                warning_info['level'] = 2
                warning_info['impact_score'] = 15
            elif warning_code == 'WFOG':
                warning_info['category'] = 'visibility'
                warning_info['subcategory'] = 'fog'
                warning_info['severity'] = 'moderate'
                warning_info['level'] = 2
                warning_info['impact_score'] = 12
        
        # 2. å¦‚æœæ²’æœ‰è­¦å‘Šä»£ç¢¼æˆ–ä»£ç¢¼æœªè­˜åˆ¥ï¼Œä½¿ç”¨æ–‡æœ¬é—œéµè©åˆ†æ
        if warning_info['category'] == 'unknown':
            if any(keyword in text_lower for keyword in ['é»‘é›¨', 'ç´…é›¨', 'é»ƒé›¨', 'æš´é›¨', 'å¤§é›¨', 'è±ªé›¨']):
                warning_info['category'] = 'rainfall'
                if 'é»‘é›¨' in text_lower:
                    warning_info['severity'] = 'extreme'
                    warning_info['level'] = 4
                    warning_info['impact_score'] = 35
                elif 'ç´…é›¨' in text_lower:
                    warning_info['severity'] = 'severe'
                    warning_info['level'] = 3
                    warning_info['impact_score'] = 25
                else:
                    warning_info['severity'] = 'moderate'
                    warning_info['level'] = 2
                    warning_info['impact_score'] = 15
            elif any(keyword in text_lower for keyword in ['é¢¨çƒ', 'é¢±é¢¨', 'ç†±å¸¶æ°£æ—‹', 'çƒˆé¢¨', 'å¼·é¢¨ä¿¡è™Ÿ', 'åè™Ÿ', 'ä¹è™Ÿ', 'å…«è™Ÿ', 'ä¸‰è™Ÿ', 'ä¸€è™Ÿ']):
                warning_info['category'] = 'wind_storm'
                if any(num in text_lower for num in ['åè™Ÿ', '10è™Ÿ', 'é¢¶é¢¨']):
                    warning_info['severity'] = 'extreme'
                    warning_info['level'] = 5
                    warning_info['impact_score'] = 40
                elif any(num in text_lower for num in ['ä¹è™Ÿ', '9è™Ÿ', 'å…«è™Ÿ', '8è™Ÿ']):
                    warning_info['severity'] = 'severe'
                    warning_info['level'] = 3
                    warning_info['impact_score'] = 25
                else:
                    warning_info['severity'] = 'moderate'
                    warning_info['level'] = 2
                    warning_info['impact_score'] = 15
            elif any(keyword in text_lower for keyword in ['é›·æš´', 'é–ƒé›»', 'é›·é›»']):
                warning_info['category'] = 'thunderstorm'
                warning_info['severity'] = 'moderate'
                warning_info['level'] = 2
                warning_info['impact_score'] = 10
            elif any(keyword in text_lower for keyword in ['éœ§', 'èƒ½è¦‹åº¦', 'è¦–é‡']):
                warning_info['category'] = 'visibility'
                warning_info['severity'] = 'moderate'
                warning_info['level'] = 2
                warning_info['impact_score'] = 12
            elif any(keyword in text_lower for keyword in ['é…·ç†±', 'é«˜æº«', 'ç‚ç†±']):
                warning_info['category'] = 'temperature'
                warning_info['subcategory'] = 'extreme_heat'
                warning_info['severity'] = 'moderate'
                warning_info['level'] = 2
                warning_info['impact_score'] = 8
            elif any(keyword in text_lower for keyword in ['å¯’å†·', 'ä½æº«', 'åš´å¯’']):
                warning_info['category'] = 'temperature'
                warning_info['subcategory'] = 'extreme_cold'
                warning_info['severity'] = 'moderate'
                warning_info['level'] = 2
                warning_info['impact_score'] = 6
            elif any(keyword in text_lower for keyword in ['æµ·äº‹', 'å¤§æµª', 'æµ·æµª', 'å°è‰‡']):
                warning_info['category'] = 'marine'
                warning_info['subcategory'] = 'marine_warning'
                warning_info['severity'] = 'moderate'
                warning_info['level'] = 2
                warning_info['impact_score'] = 8
            elif any(keyword in text_lower for keyword in ['ç©ºæ°£æ±¡æŸ“', 'pm2.5', 'pm10', 'è‡­æ°§']):
                warning_info['category'] = 'air_quality'
                warning_info['subcategory'] = 'pollution'
                warning_info['severity'] = 'moderate'
                warning_info['level'] = 2
                warning_info['impact_score'] = 6
        
        # 3. æª¢æŸ¥åœ°å€ç‰¹å®šè­¦å‘Š
        if any(region in text_lower for region in ['æ–°ç•Œ', 'æ¸¯å³¶', 'ä¹é¾', 'é›¢å³¶', 'åŒ—å€', 'æ±å€', 'å¤§å¶¼å±±']):
            warning_info['area_specific'] = True
        
        # 4. æª¢æŸ¥æ™‚é–“ç›¸é—œæç¤º
        if any(time_word in text_lower for time_word in ['æŒçºŒ', 'é è¨ˆ', 'æœªä¾†', 'å³å°‡', 'ç¨å¾Œ']):
            warning_info['duration_hint'] = 'æŒçºŒæ€§è­¦å‘Š'
        elif any(time_word in text_lower for time_word in ['çŸ­æš«', 'é–“æ­‡', 'å±€éƒ¨']):
            warning_info['duration_hint'] = 'é–“æ­‡æ€§è­¦å‘Š'
        
        return warning_info
    
    def _assess_data_quality(self) -> Dict:
        """è©•ä¼°æ•¸æ“šè³ªé‡"""
        conn = sqlite3.connect(self.db_path)
        
        # çµ±è¨ˆå„è¡¨çš„æ•¸æ“šé‡
        warning_count = pd.read_sql_query("SELECT COUNT(*) as count FROM warning_records", conn).iloc[0]['count']
        prediction_count = pd.read_sql_query("SELECT COUNT(*) as count FROM prediction_records", conn).iloc[0]['count']
        
        # æª¢æŸ¥æ•¸æ“šå®Œæ•´æ€§
        incomplete_warnings = pd.read_sql_query(
            "SELECT COUNT(*) as count FROM warning_records WHERE category = 'unknown'", 
            conn
        ).iloc[0]['count']
        
        conn.close()
        
        quality_score = 100
        issues = []
        
        if warning_count < 10:
            quality_score -= 30
            issues.append("è­¦å‘Šæ•¸æ“šé‡ä¸è¶³ï¼Œå»ºè­°æ”¶é›†æ›´å¤šæ­·å²æ•¸æ“š")
        
        if prediction_count < 5:
            quality_score -= 20
            issues.append("é æ¸¬æ•¸æ“šé‡ä¸è¶³ï¼Œå»ºè­°é€²è¡Œæ›´å¤šé æ¸¬è¨˜éŒ„")
        
        if incomplete_warnings > warning_count * 0.1:
            quality_score -= 25
            issues.append("å­˜åœ¨è¼ƒå¤šæœªè­˜åˆ¥çš„è­¦å‘Šé¡å‹ï¼Œå»ºè­°æ”¹é€²è§£æé‚è¼¯")
        
        return {
            "overall_score": max(0, quality_score),
            "data_counts": {
                "warnings": warning_count,
                "predictions": prediction_count,
                "incomplete_warnings": incomplete_warnings
            },
            "issues": issues,
            "recommendations": [
                "å®šæœŸåŸ·è¡Œæ•¸æ“šåˆ†æä»¥ç›£æ§æ•¸æ“šè³ªé‡",
                "å»ºç«‹è‡ªå‹•åŒ–æ•¸æ“šæ”¶é›†æµç¨‹",
                "å®šæœŸæ›´æ–°è­¦å‘Šè§£æè¦å‰‡"
            ]
        }

def demo_warning_analysis():
    """ç¤ºç¯„è­¦å‘Šåˆ†æåŠŸèƒ½"""
    print("ğŸ” è­¦å‘Šæ­·å²æ•¸æ“šåˆ†æç³»çµ± - åŠŸèƒ½æ¼”ç¤º")
    print("=" * 60)
    
    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = WarningHistoryAnalyzer()
    
    # æ¨¡æ“¬ä¸€äº›æ­·å²è­¦å‘Šæ•¸æ“š
    sample_warnings = [
        "é»‘è‰²æš´é›¨è­¦å‘Šä¿¡è™Ÿç¾æ­£ç”Ÿæ•ˆ",
        "å…«è™Ÿçƒˆé¢¨ä¿¡è™Ÿç¾æ­£ç”Ÿæ•ˆ",
        "é›·æš´è­¦å‘Š",
        "å¤§éœ§è­¦å‘Š",
        "ç´…è‰²æš´é›¨è­¦å‘Šä¿¡è™Ÿç¾æ­£ç”Ÿæ•ˆ",
        "ä¸‰è™Ÿå¼·é¢¨ä¿¡è™Ÿç¾æ­£ç”Ÿæ•ˆ"
    ]
    
    print(f"\nğŸ“ æ¨¡æ“¬è¨˜éŒ„ {len(sample_warnings)} å€‹è­¦å‘Š...")
    for warning in sample_warnings:
        analyzer.record_warning({"warning_text": warning})
    
    # æ¨¡æ“¬ä¸€äº›é æ¸¬æ•¸æ“š
    sample_predictions = [
        {
            "prediction_type": "sunset",
            "advance_hours": 0,
            "original_score": 75,
            "warning_impact": 15,
            "warning_risk_impact": 0,
            "final_score": 60,
            "warnings_active": ["å…«è™Ÿçƒˆé¢¨ä¿¡è™Ÿ"]
        },
        {
            "prediction_type": "sunset", 
            "advance_hours": 2,
            "original_score": 80,
            "warning_impact": 25,
            "warning_risk_impact": 5,
            "final_score": 50,
            "warnings_active": ["é»‘è‰²æš´é›¨è­¦å‘Š"]
        }
    ]
    
    print(f"\nğŸ“ˆ æ¨¡æ“¬è¨˜éŒ„ {len(sample_predictions)} å€‹é æ¸¬...")
    for prediction in sample_predictions:
        analyzer.record_prediction(prediction)
    
    # åŸ·è¡Œåˆ†æ
    print(f"\nğŸ” åŸ·è¡Œè­¦å‘Šæ¨¡å¼åˆ†æ...")
    patterns = analyzer.analyze_warning_patterns(30)
    print(f"   - ç¸½è­¦å‘Šæ•¸: {patterns.get('total_warnings', 0)}")
    print(f"   - è­¦å‘Šé¡åˆ¥åˆ†å¸ƒ: {patterns.get('category_distribution', {})}")
    
    print(f"\nğŸŒ åŸ·è¡Œå­£ç¯€æ€§è¶¨å‹¢åˆ†æ...")
    seasonal = analyzer.analyze_seasonal_trends()
    if 'seasonal_comparison' in seasonal:
        print(f"   - æœ€æ´»èºå­£ç¯€: {seasonal['seasonal_comparison'].get('most_active_season', 'N/A')}")
    
    print(f"\nğŸ“Š åŸ·è¡Œé æ¸¬æº–ç¢ºæ€§è©•ä¼°...")
    accuracy = analyzer.evaluate_prediction_accuracy(7)
    print(f"   - è©•ä¼°æœŸé–“: {accuracy.get('evaluation_period', 'N/A')}")
    print(f"   - ç¸½é æ¸¬æ•¸: {accuracy.get('total_predictions', 0)}")
    
    print(f"\nğŸ’¡ ç”Ÿæˆæ´å¯Ÿå’Œå»ºè­°...")
    insights = analyzer.generate_warning_insights()
    recommendations = insights.get('recommendations', [])
    for i, rec in enumerate(recommendations, 1):
        print(f"   {i}. {rec}")
    
    # å°å‡ºå ±å‘Š
    print(f"\nğŸ“„ å°å‡ºåˆ†æå ±å‘Š...")
    report_file = analyzer.export_analysis_report()
    
    print(f"\nâœ… è­¦å‘Šæ­·å²æ•¸æ“šåˆ†ææ¼”ç¤ºå®Œæˆï¼")
    print(f"ğŸ“Š è©³ç´°å ±å‘Šå·²ä¿å­˜è‡³: {report_file}")
    
    return analyzer

if __name__ == "__main__":
    demo_warning_analysis()
